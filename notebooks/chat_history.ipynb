{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Chat History Management\n",
    "In the [LangChain Expression Language (LCEL)](./lcel.ipynb), we covered LCEL at a high level, demonstrating specifically how to chain a prompt engineered chat prompt with an LLM, namely MLX. What I failed to demonstrate in that notebook was how to think about memory (aka chat conversation management), and to be honest, I underestimated how \"involved\" of a thing this got to be! ðŸ˜… To be clear, what we will be covering in this notebook is less of a technical concern and more of a business logic concern.\n",
    "\n",
    "While LangChain offers many mechanisms for handling chat conversations (aka memory) correctly, I found some of the higher level ones to not be satisfactory for our purposes. Specifically, since I want us to adhere to a fixed schema, the high level abstraction objects provided by LangChain simply don't operate in the ideal way in which we need them to. No worries! We can still work around this without having to abandon LangChain. We're just going to need to do some special stuff throughout this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Flow\n",
    "Before we get into the code itself, let's talk about how we want to think about the flow. For simplicity's sake, we are going to be ultimately saving this chat history as a JSON file. This JSON file should look like the schema that we've defined in the file `data/schema.json`.\n",
    "\n",
    "Let's say that the user is loading the MLX Gradio UI interface, either for the first time ever or as a returning user. Here is the flow of how we should be thinking about our data:\n",
    "\n",
    "1. **Loading the chat history from file**: Just as it sounds, we will want to load the chat history from file so that the user can interact with their historical conversations if they would like. Now, it's possible that this is the user's first time interacting with the chatbot, so it may be that we need to create this file from scratch!\n",
    "2. **Setting a new conversation ID**: Regardless if the user is new or returning, we are going to make the assumption that the user will want to begin with a new conversation. This means that we will need to instantiate a new conversation ID so that we can keep appending new conversation interactions to that same conversation thread.\n",
    "3. **Managing conversation back-and-forth**: As the conversation proceeds, we will want to continually update our conversation schema with any new human and AI interactions. This will include also autosaving them to file for the user's convenience.\n",
    "4. **Starting a new conversation / loading an existing conversation**: At any point, the user may want to pivot from their current conversation to either a new conversation or to continue another historical conversation loaded from our file as part of step 1. If this is the case, we will need to ensure that our backend system is referencing the correct conversation interaction.\n",
    "\n",
    "To really drive home the point, we will actually jump back and forth between each of these use cases to ensure that everything works seamlessly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "In this section, we'll do all our usual set ups. We'll also set up the LangChain MLX model using the new ChatMLX implementation. All these are things we've already explored in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import copy\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.llms.mlx_pipeline import MLXPipeline\n",
    "from langchain_community.chat_models.mlx import ChatMLX\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.chat_message_histories.in_memory import ChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting constant values to represent model name and directory\n",
    "MODEL_NAME = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "BASE_DIRECTORY = '../models'\n",
    "MLX_DIRECTORY = f'{BASE_DIRECTORY}/mlx'\n",
    "mlx_model_directory = f'{MLX_DIRECTORY}/{MODEL_NAME}'\n",
    "\n",
    "# Setting a constant value to represent where to place the chat history data\n",
    "CHAT_HISTORY_DIRECTORY = '../data'\n",
    "chat_history_json_location = f'{CHAT_HISTORY_DIRECTORY}/chat_history.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a default system prompt\n",
    "DEFAULT_SYSTEM_PROMPT = 'You are a helpful assistant.'\n",
    "\n",
    "class MLXModelParameters():\n",
    "\n",
    "    def __init__(self, model_name = MODEL_NAME, temp = 0.7, max_tokens = 1000, system_prompt = DEFAULT_SYSTEM_PROMPT):\n",
    "        self.model_name = model_name\n",
    "        self.temp = temp\n",
    "        self.max_tokens = max_tokens\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Model Name: {self.model_name}\\nTemperature: {self.temp}\\nMax Tokens: {self.max_tokens}\\nSystem Prompt: {self.system_prompt}'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Model Name: {self.model_name}\\nTemperature: {self.temp}\\nMax Tokens: {self.max_tokens}\\System Prompt: {self.system_prompt}'\n",
    "    \n",
    "    def update_model_name(self, new_model_name):\n",
    "        self.model_name = new_model_name\n",
    "\n",
    "    def update_temp(self, new_temp):\n",
    "        self.temp = new_temp\n",
    "\n",
    "    def update_max_tokens(self, new_max_tokens):\n",
    "        self.max_tokens = new_max_tokens\n",
    "\n",
    "    def update_system_prompt(self, new_system_prompt):\n",
    "        self.system_prompt = new_system_prompt\n",
    "\n",
    "    def to_json(self):\n",
    "        return { 'temp': self.temp, 'max_tokens': self.max_tokens }\n",
    "    \n",
    "mlx_model_parameters = MLXModelParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Setting up the LangChain MLX LLM\n",
    "llm = MLXPipeline.from_model_id(\n",
    "    model_id = mlx_model_directory,\n",
    "    pipeline_kwargs = {\n",
    "        'temp': mlx_model_parameters.temp,\n",
    "        'max_tokens': mlx_model_parameters.max_tokens,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Setting up the LangChain MLX Chat Model with the LLM above\n",
    "chat_model = ChatMLX(llm = llm)\n",
    "\n",
    "# NOTE: The commented out code below will overwrite the MLX chat model with OpenAI. I did this out of curiosity, because theoretically, this should have worked just fine. And it did! I'm pretty thrilled about it!\n",
    "# import yaml\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# with open('../sensitive/api-keys.yaml') as f:\n",
    "#     API_KEYS = yaml.safe_load(f)\n",
    "\n",
    "# chat_model = ChatOpenAI(api_key = API_KEYS['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the LangChain inference pipeline\n",
    "In order to use LangChain's preferred implementation of memory management, we're first going to need to establish our LangChain pipeline. We've done similar things to this in other notebooks, but with this particular implementation, we are going to make a specific adjustment. Namely, since we are now going to make use of the LangChain Community implementation of MLX, we are going to need to manually add our own metadata. To seamlessly do this, we are going to make use of LCEL's **RunnableLambda**, which essentially allows us to define our own custom function.\n",
    "\n",
    "Also note that when we set up our chat prompt, we are going to need to slide in an extra entry referred to as **MessagesPlaceholder**. As the name implies, that will serve as a placeholder so that we can keep passing the history back through the model.\n",
    "\n",
    "Another item of note: Specific models like Llama or Mistral **do not** natively accept system messages. As a result, we're going to have to use that same **RunnableLambda** object to create another custom function that manages that appropriate conversion for those models.\n",
    "\n",
    "To put it all together, here are the steps of our inference pipeline:\n",
    "\n",
    "1. **Chat prompt**: This is the prompt engineering structure that we'll be eventually passing into the model. As mentioned above, this will also use the `MessagesPlaceholder` object to manage the history.\n",
    "2. **Correct for \"No System\" models**: Because model providers like Meta and Mistral do not natively accept system messsages, this step in the pipeline will use the LCEL's `RunnableLambda` to create a custom function taht corrects for this issue manually.\n",
    "3. **Invoke the model with MLX**: Pretty self explanatory. This is the step where we pass in our messages and any history to produce a response from the model.\n",
    "4. **Update the AI message metadata**: Because LangChain's MLX object does not place any metadata on the AI message coming out of the MLX model, we are going to have to use another `RunnableLambda` here with a custom function that will allow us to manually add that metadata>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Chat prompt template\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(messages = [\n",
    "    SystemMessage(content = mlx_model_parameters.system_prompt),\n",
    "    MessagesPlaceholder(variable_name = 'history'),\n",
    "    HumanMessagePromptTemplate.from_template(template = '{input}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_for_no_system_models(chat_messages):\n",
    "    '''\n",
    "    Precorrects for the issue where certain models (e.g. Llama, Mistral) are unable to accept for system messages\n",
    "\n",
    "    Inputs:\n",
    "        - chat_messages (LangChain ChatPromptValue): The current chat messages with no alterations\n",
    "\n",
    "    Returns:\n",
    "        - chat_messages (LangChain ChatPromptValue): The new chat messages with alterations (if needed)\n",
    "    '''\n",
    "    \n",
    "    # Referencing MLX model parameters as a global object\n",
    "    global mlx_model_parameters\n",
    "    \n",
    "    # Setting a list of models that we'll need to check against\n",
    "    NO_SYSTEM_MODEL_PROVIDERS = ['mistralai', 'meta-llama']\n",
    "\n",
    "    # Checking if the correction needs to be made if the model is Llama or Mistral\n",
    "    if mlx_model_parameters.model_name.split('/')[0] in NO_SYSTEM_MODEL_PROVIDERS:\n",
    "\n",
    "        # Getting the system message content\n",
    "        system_message_content = chat_messages.messages[0].content\n",
    "\n",
    "        # Replacing the System Message with a Human Message\n",
    "        chat_messages.messages[0] = HumanMessage(content = system_message_content)\n",
    "\n",
    "        # Adds a dummy AI Message\n",
    "        chat_messages.messages.insert(1, AIMessage(content = ''))\n",
    "\n",
    "    return chat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ai_response_metadata(ai_message):\n",
    "    '''\n",
    "    Updates the metadata on the AI response\n",
    "\n",
    "    Inputs:\n",
    "        - ai_message (LangChain AIMessage): The AI message produced by the model\n",
    "\n",
    "    Returns:\n",
    "        - ai_message (LangChain AIMessage): The AI message produced by the model, except now with the appropriate metadata intact\n",
    "    '''\n",
    "\n",
    "    # Referencing MLX model parameters as a global object\n",
    "    global mlx_model_parameters\n",
    "\n",
    "    # Creating a dictionary of the metadata that we will be adding to the AI message\n",
    "    metadata = {\n",
    "        'model_name': mlx_model_parameters.model_name,\n",
    "        'timestamp': str(pd.Timestamp.utcnow()),\n",
    "        'like_data': None,\n",
    "        'hyperparameters': mlx_model_parameters.to_json()\n",
    "    }\n",
    "\n",
    "    # Applying the metadata to the AI response\n",
    "    ai_message.response_metadata = metadata\n",
    "\n",
    "    return ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the inference chain by chaining together the chat prompt, chat model, and custom function to update metadata\n",
    "inference_chain = chat_prompt_template | RunnableLambda(correct_for_no_system_models) | chat_model | RunnableLambda(update_ai_response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest city in Illinois is Chicago. Chicago is the third most populous city in the United States and the most populous city in the Midwest. It is located in the northeastern part of Illinois and is known for its iconic skyline, major industries, cultural institutions, and its role as a global hub for commerce, transportation, and technology.\n"
     ]
    }
   ],
   "source": [
    "# Generating the response with the first prompt\n",
    "response = inference_chain.invoke({\n",
    "    'history': [\n",
    "        HumanMessage(content = 'What is the capital of Illinois?'),\n",
    "        AIMessage(content = 'The capital of Illinois is Sprinfield.')\n",
    "    ],\n",
    "    'input': 'What is the largest city in that state?'\n",
    "})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing the Conversation History\n",
    "Now that we have instantiated our inference pipeline, we are ready to talk about managing the conversation history. The way that LangChain recommends to do this is by using this object called `RunnableWithMessageHistory`. What this function does is take in our \"runnable\" inference pipeline, and anything that is invoked from that gets added to the chat history over time. The nice thing about this object is that at the time of inference, you can also pass in a unique session ID and manage chat histories by that unique session ID. We'll demonstrate how we can use this to easily pivot back and forth between various conversations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an empty dictionary to represent the user's LangChain (lc) conversation history\n",
    "lc_user_conversation_history = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    '''\n",
    "    Gets the conversation session history per a uniquely input session ID\n",
    "\n",
    "    Inputs:\n",
    "        - session_id (str): A unique ID representing the current conversation session\n",
    "\n",
    "    Returns:\n",
    "        - lc_user_conversation_history[session_id] (LangChain BaseChatMessageHistory): A LangChain history object with the history of the conversation per the respective session ID\n",
    "    '''\n",
    "    if session_id not in lc_user_conversation_history:\n",
    "        lc_user_conversation_history[session_id] = ChatMessageHistory()\n",
    "\n",
    "    return lc_user_conversation_history[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a LangChain invokable that will run the inference pipeline and also manage chat history\n",
    "inference_chain_w_history = RunnableWithMessageHistory(\n",
    "    runnable = inference_chain,\n",
    "    get_session_history = get_session_history,\n",
    "    input_messages_key = 'input',\n",
    "    history_messages_key = 'history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 demo IDs\n",
    "demo_id_1 = 'conv_id_' + str.replace(str(uuid.uuid4()), '-', '_')\n",
    "demo_id_2 = 'conv_id_' + str.replace(str(uuid.uuid4()), '-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The largest city in California by population is Los Angeles. Los Angeles is located in the southern part of the state and is known for its iconic Hollywood film industry, diverse cultural scene, and world-renowned attractions such as the Hollywood Walk of Fame, Griffith Observatory, and Universal Studios Hollywood. According to the latest US Census data, the population of Los Angeles County, which includes the city of Los Angeles, is over 10 million people, making it the most populous county', response_metadata={'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'timestamp': '2024-05-02 14:56:34.368788+00:00', 'like_data': None, 'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}, id='run-88214bde-5a26-40dd-a3c3-eecaf2d587ed-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the model twice while passing in the session ID to manage the history\n",
    "inference_chain_w_history.invoke(\n",
    "    input = {'input': 'What is the capital of Illinois?'},\n",
    "    config = {\n",
    "        'configurable': {\n",
    "            'session_id': demo_id_1\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "inference_chain_w_history.invoke(\n",
    "    input = {'input': 'What is the largest city in that state?'},\n",
    "    config = {\n",
    "        'configurable': {\n",
    "            'session_id': demo_id_1\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "inference_chain_w_history.invoke(\n",
    "    input = {'input': 'What is the capital of California?'},\n",
    "    config = {\n",
    "        'configurable': {\n",
    "            'session_id': demo_id_2\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "inference_chain_w_history.invoke(\n",
    "    input = {'input': 'What is the largest city in that state?'},\n",
    "    config = {\n",
    "        'configurable': {\n",
    "            'session_id': demo_id_2\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_id_4c49e021_4dc1_4b2f_9892_511e810fb7e3': ChatMessageHistory(messages=[HumanMessage(content='What is the capital of Illinois?'), AIMessage(content=\"The capital city of Illinois is Springfield. It's located in the central part of the state and is the county seat of Sangamon County. Springfield is known for its rich history, including being the site of Abraham Lincoln's presidential library and his former home, which is now a National Historic Site.\", response_metadata={'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'timestamp': '2024-05-02 14:56:24.750245+00:00', 'like_data': None, 'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}, id='run-73e2b3b4-e799-4e0c-8234-a91fb956bb50-0'), HumanMessage(content='What is the largest city in that state?'), AIMessage(content=\"The largest city in Illinois is Chicago. Chicago is located in the northeastern part of the state and is the third most populous city in the United States. It's known for its iconic skyline, major industries, cultural institutions, and its role as a global hub for commerce, transportation, and technology. Chicago is also famous for its architecture, museums, and its food scene, particularly its deep-dish pizza and Chicago-style hot dogs.\", response_metadata={'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'timestamp': '2024-05-02 14:56:28.233835+00:00', 'like_data': None, 'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}, id='run-ce12861c-0c62-4830-9743-46b9e44ea9dd-0')]), 'conv_id_8731679f_426f_4e89_b0ce_97157ac81697': ChatMessageHistory(messages=[HumanMessage(content='What is the capital of California?'), AIMessage(content=\"The capital city of California is Sacramento. Sacramento is located in the central part of the state and is known for its rich history, cultural diversity, and various attractions such as Old Sacramento, the California State Capitol, and the California State Railroad Museum. It's also the seat of government for California and is home to various state government offices and agencies.\", response_metadata={'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'timestamp': '2024-05-02 14:56:30.731418+00:00', 'like_data': None, 'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}, id='run-b41d0c76-0199-4579-9372-937e07f4ddb5-0'), HumanMessage(content='What is the largest city in that state?'), AIMessage(content='The largest city in California by population is Los Angeles. Los Angeles is located in the southern part of the state and is known for its iconic Hollywood film industry, diverse cultural scene, and world-renowned attractions such as the Hollywood Walk of Fame, Griffith Observatory, and Universal Studios Hollywood. According to the latest US Census data, the population of Los Angeles County, which includes the city of Los Angeles, is over 10 million people, making it the most populous county', response_metadata={'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'timestamp': '2024-05-02 14:56:34.368788+00:00', 'like_data': None, 'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}, id='run-88214bde-5a26-40dd-a3c3-eecaf2d587ed-0')])}\n",
      "\n",
      "\n",
      "Human: What is the capital of Illinois?\n",
      "AI: The capital city of Illinois is Springfield. It's located in the central part of the state and is the county seat of Sangamon County. Springfield is known for its rich history, including being the site of Abraham Lincoln's presidential library and his former home, which is now a National Historic Site.\n",
      "Human: What is the largest city in that state?\n",
      "AI: The largest city in Illinois is Chicago. Chicago is located in the northeastern part of the state and is the third most populous city in the United States. It's known for its iconic skyline, major industries, cultural institutions, and its role as a global hub for commerce, transportation, and technology. Chicago is also famous for its architecture, museums, and its food scene, particularly its deep-dish pizza and Chicago-style hot dogs.\n",
      "\n",
      "\n",
      "Human: What is the capital of California?\n",
      "AI: The capital city of California is Sacramento. Sacramento is located in the central part of the state and is known for its rich history, cultural diversity, and various attractions such as Old Sacramento, the California State Capitol, and the California State Railroad Museum. It's also the seat of government for California and is home to various state government offices and agencies.\n",
      "Human: What is the largest city in that state?\n",
      "AI: The largest city in California by population is Los Angeles. Los Angeles is located in the southern part of the state and is known for its iconic Hollywood film industry, diverse cultural scene, and world-renowned attractions such as the Hollywood Walk of Fame, Griffith Observatory, and Universal Studios Hollywood. According to the latest US Census data, the population of Los Angeles County, which includes the city of Los Angeles, is over 10 million people, making it the most populous county\n"
     ]
    }
   ],
   "source": [
    "# Viewing the current user conversation history\n",
    "print(lc_user_conversation_history)\n",
    "print('\\n')\n",
    "print(lc_user_conversation_history[demo_id_1])\n",
    "print('\\n')\n",
    "print(lc_user_conversation_history[demo_id_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Generating a Summary Title\n",
    "In certain interfaces including OpenAI's ChatGPT, the chat history will represent your conversation with what I like to call a \"summary title.\" For example, let's say I ask it for a recipe for chocolate chip cookies, then the ChatGPT interface will represent my conversation in the chat history window as something like \"A Recipe for Chocolate Chip Cookies\". While this is not necessary, I thought it might be a fun touch to add!\n",
    "\n",
    "Let's demonstrate by starting a conversation asking it to write a fun haiku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_title(lc_current_session_history, chat_model):\n",
    "    '''\n",
    "    Generates a summary title based on the user's initial interaction with the MLX model\n",
    "\n",
    "    Inputs:\n",
    "        - lc_current_session_history (LangChain ChatMessageHistory): A list of messages representing the current session conversation history\n",
    "        - chat_model (LangChain MLX ChatModel): The chat model used to generate the summary title\n",
    "\n",
    "    Returns:\n",
    "        - summary_title (str): The summary title from the user's initial interaction with the MLX model\n",
    "    '''\n",
    "\n",
    "    # Referencing MLX model parameters as a global object\n",
    "    global mlx_model_parameters\n",
    "\n",
    "    # Creating the summary title prompt engineering\n",
    "    summary_title_prompt = '''The text delineated by the triple backticks below contains the beginning of a conversation between a human and a large language model (LLM). Please provide a brief summary to serve as a title for this conversation. Do not use any system messages. Place more emphasis on the human's prompt over the AI's response. Please ensure the summary title does not exceed more than ten words. Please format the summary title as one would any formal title, like that of a book. Do not give any extra words except the summary title. (Example: Do not show \"Title: \") Please ensure that the length of the output is no longer than 10 words.\n",
    "\n",
    "    ```\n",
    "    {history}\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "    # Creating the summary title chat prompt\n",
    "    summary_title_chat_prompt = ChatPromptTemplate.from_messages(messages = [\n",
    "        HumanMessagePromptTemplate.from_template(template = summary_title_prompt)\n",
    "    ])\n",
    "\n",
    "    # Creating a simple chain to produce the summary title\n",
    "    summary_title_chain = summary_title_chat_prompt | chat_model\n",
    "    \n",
    "    # Getting just the first interaction from the chat message history\n",
    "    initial_interaction = lc_current_session_history.messages[:2]\n",
    "\n",
    "    # Generating the summary title based on the sample chat history\n",
    "    summary_title_response = summary_title_chain.invoke({\n",
    "        'history': initial_interaction\n",
    "    })\n",
    "\n",
    "    # Stripping out \"Title: \" (Because no idea why it wants to keep doing that...)\n",
    "    summary_title = summary_title_response.content.replace(\"Title: \", \"\").replace(\"title: \", \"\")\n",
    "\n",
    "    return summary_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital City of Illinois: Springfield\n",
      "Capital City of California: Sacramento\n"
     ]
    }
   ],
   "source": [
    "# Producing a summary title based on our demo sessions\n",
    "summary_title_1 = generate_summary_title(lc_current_session_history = lc_user_conversation_history[demo_id_1], chat_model = chat_model)\n",
    "print(summary_title_1)\n",
    "summary_title_2 = generate_summary_title(lc_current_session_history = lc_user_conversation_history[demo_id_2], chat_model = chat_model)\n",
    "print(summary_title_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the User History Schema\n",
    "As mentioned before, we are going to be emulating the structure of the schema as defined in `data/schema.json`. In this notebook, we are going to pretend as if the user is a brand new user, so we will need to set up the conversation history schema from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'default_username', 'chat_history': {}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the base conversation history schema per a single user\n",
    "BASE_USER_CONVERSATION_HISTORY_SCHEMA = {\n",
    "    'user_id': 'default_username',\n",
    "    'chat_history': {}\n",
    "}\n",
    "\n",
    "BASE_USER_CONVERSATION_HISTORY_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the user history from the base schema\n",
    "user_history = copy.deepcopy(BASE_USER_CONVERSATION_HISTORY_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'default_username', 'chat_history': {}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the LangChain Messages to JSON\n",
    "One great thing about LangChain are the many integrations it offers for connections to many of your favorite online services. To keep things simple, I want to save my chat history as a JSON file. Now as you saw in the previous section, I'm a bit picky with my choice of schema. This means that we are going to need to figure out a way to convert the LangChain messages to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_session_to_json_session(lc_current_session_history):\n",
    "    '''\n",
    "    Converts the current LangChain session history to a JSON session history\n",
    "\n",
    "    Inputs:\n",
    "        - lc_current_session_history (LangChain ChatMessageHistory): The LangChain session history\n",
    "\n",
    "    Returns:\n",
    "        - json_current_session_history (list): The LangChain session history now transformed into JSON session history\n",
    "    '''\n",
    "    # Instantiating a list to hold the JSON outputs\n",
    "    json_current_session_history = []\n",
    "\n",
    "    # Converting the LangChain messages using LangChain's built in json() function\n",
    "    lc_generated_json = json.loads(lc_current_session_history.json())\n",
    "\n",
    "    # Iterating over each of the LangChain messages\n",
    "    for message in lc_generated_json['messages']:\n",
    "\n",
    "        # Determining the action based on if message is Human type\n",
    "        if message['type'] == 'human':\n",
    "\n",
    "            conversation_json = {\n",
    "                'role': 'user',\n",
    "                'content': message['content'],\n",
    "            }\n",
    "            json_current_session_history.append(conversation_json)\n",
    "        \n",
    "        # Determining the action based on if message is AI type\n",
    "        elif message['type'] == 'ai':\n",
    "\n",
    "            conversation_json = {\n",
    "                'role': 'assistant',\n",
    "                'content': message['content'],\n",
    "                'metadata': message['response_metadata']\n",
    "            }\n",
    "            json_current_session_history.append(conversation_json)\n",
    "        \n",
    "    return json_current_session_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'default_username',\n",
       " 'chat_history': {'conv_id_4c49e021_4dc1_4b2f_9892_511e810fb7e3': [{'role': 'user',\n",
       "    'content': 'What is the capital of Illinois?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"The capital city of Illinois is Springfield. It's located in the central part of the state and is the county seat of Sangamon County. Springfield is known for its rich history, including being the site of Abraham Lincoln's presidential library and his former home, which is now a National Historic Site.\",\n",
       "    'metadata': {'model_name': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       "     'timestamp': '2024-05-02 14:56:24.750245+00:00',\n",
       "     'like_data': None,\n",
       "     'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}},\n",
       "   {'role': 'user', 'content': 'What is the largest city in that state?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"The largest city in Illinois is Chicago. Chicago is located in the northeastern part of the state and is the third most populous city in the United States. It's known for its iconic skyline, major industries, cultural institutions, and its role as a global hub for commerce, transportation, and technology. Chicago is also famous for its architecture, museums, and its food scene, particularly its deep-dish pizza and Chicago-style hot dogs.\",\n",
       "    'metadata': {'model_name': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       "     'timestamp': '2024-05-02 14:56:28.233835+00:00',\n",
       "     'like_data': None,\n",
       "     'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}}],\n",
       "  'conv_id_8731679f_426f_4e89_b0ce_97157ac81697': [{'role': 'user',\n",
       "    'content': 'What is the capital of California?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"The capital city of California is Sacramento. Sacramento is located in the central part of the state and is known for its rich history, cultural diversity, and various attractions such as Old Sacramento, the California State Capitol, and the California State Railroad Museum. It's also the seat of government for California and is home to various state government offices and agencies.\",\n",
       "    'metadata': {'model_name': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       "     'timestamp': '2024-05-02 14:56:30.731418+00:00',\n",
       "     'like_data': None,\n",
       "     'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}},\n",
       "   {'role': 'user', 'content': 'What is the largest city in that state?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'The largest city in California by population is Los Angeles. Los Angeles is located in the southern part of the state and is known for its iconic Hollywood film industry, diverse cultural scene, and world-renowned attractions such as the Hollywood Walk of Fame, Griffith Observatory, and Universal Studios Hollywood. According to the latest US Census data, the population of Los Angeles County, which includes the city of Los Angeles, is over 10 million people, making it the most populous county',\n",
       "    'metadata': {'model_name': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       "     'timestamp': '2024-05-02 14:56:34.368788+00:00',\n",
       "     'like_data': None,\n",
       "     'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}}}]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating the user history with our demo conversation histories converted now to JSON\n",
    "user_history['chat_history'][demo_id_1] = lc_session_to_json_session(lc_current_session_history = lc_user_conversation_history[demo_id_1])\n",
    "user_history['chat_history'][demo_id_2] = lc_session_to_json_session(lc_current_session_history = lc_user_conversation_history[demo_id_2])\n",
    "user_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardening the Inference Pipeline\n",
    "Okay, we've come a long way so far! Let's quickly recap what we've covered so far. We have built the following things:\n",
    "\n",
    "1. **Inference pipeline**: This is the \"barebones\" inference pipeline that we invoke to get a response from MLX. Because there are a few little gotchas, we had to address things like manually adding the AI message metadata as part of this step.\n",
    "2. **Inference pipeline with history**: The first step did NOT manage conversation history at all. In this second step, we introduced how to manage the conversation history, and we specifically did so by being able to swap back and forth between conversations using a unique session ID.\n",
    "3. **(Optional) Summary title**: This part isn't necessary, but I thought it was a nice touch. This step takes the initial interaction between the user and the AI to produce a \"summary title\" that we can later use for our a nice display thing in our MLX Gradio chat history.\n",
    "4. **User history schema**: In this section, we instantiated the expected user history schema based on the schema we manually created in the file `data/schema.json`.\n",
    "5. **LangChain current session history to JSON**: This step covered how we can convert the LangChain session history into a JSON object that we can later save to / load from a local file.\n",
    "\n",
    "We're going to put it all together now! We're going to harden our inference pipeline by creating a massive \"meta\" function encapsulates all our functionality here plus saves the user's chat history out every time we interact with the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model(prompt_text, current_session_id):\n",
    "    '''\n",
    "    Invokes the model using MLX and saves chat history back to a local file\n",
    "\n",
    "    Inputs:\n",
    "        - prompt_text (str): The prompt text submitted by the user\n",
    "        - current_session_id (str): The current session ID\n",
    "\n",
    "    Returns\n",
    "        - response (str): The response from the AI model per the input prompt\n",
    "    '''\n",
    "    # Referencing global variables\n",
    "    global lc_user_conversation_history\n",
    "    global user_history\n",
    "    global chat_history_json_location\n",
    "    global chat_model\n",
    "    global chat_prompt_template\n",
    "    global mlx_model_parameters\n",
    "\n",
    "    # Creating the inference chain by chaining together the chat prompt, chat model, and custom function to update metadata\n",
    "    inference_chain = chat_prompt_template | RunnableLambda(correct_for_no_system_models) | chat_model | RunnableLambda(update_ai_response_metadata)\n",
    "\n",
    "    # Creating a LangChain invokable that will run the inference pipeline and also manage chat history\n",
    "    inference_chain_w_history = RunnableWithMessageHistory(\n",
    "        runnable = inference_chain,\n",
    "        get_session_history = get_session_history,\n",
    "        input_messages_key = 'input',\n",
    "        history_messages_key = 'history'\n",
    "    )\n",
    "\n",
    "    # Invoking the model with the user's input prompt and current session ID\n",
    "    response = inference_chain_w_history.invoke(\n",
    "        input = {'input': prompt_text},\n",
    "        config = {\n",
    "            'configurable': {\n",
    "                'session_id': current_session_id\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Updating the user history with our demo conversation histories converted now to JSON\n",
    "    user_history['chat_history'][current_session_id] = {\n",
    "        'conversation': lc_session_to_json_session(lc_current_session_history = lc_user_conversation_history[current_session_id])\n",
    "    }\n",
    "\n",
    "    # If not added already, adding the system prompt to the current session\n",
    "    if 'system_prompt' not in user_history['chat_history'][current_session_id].keys():\n",
    "        user_history['chat_history'][current_session_id]['system_prompt'] = mlx_model_parameters.system_prompt\n",
    "\n",
    "    # If not added already, adding the summary title to the current session\n",
    "    if 'summary_title' not in user_history['chat_history'][current_session_id].keys():\n",
    "        user_history['chat_history'][current_session_id]['summary_title'] = generate_summary_title(lc_current_session_history = lc_user_conversation_history[current_session_id], chat_model = chat_model)\n",
    "\n",
    "    # Writing the full history back to file\n",
    "    with open(chat_history_json_location, 'w') as f:\n",
    "        json.dump(user_history, f, indent = 4)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the user's history from scratch\n",
    "lc_user_conversation_history = {}\n",
    "user_history = copy.deepcopy(BASE_USER_CONVERSATION_HISTORY_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The largest city in California by population is Los Angeles. Los Angeles is located in the southern part of the state and is known for its iconic Hollywood film industry, diverse cultural scene, and world-renowned attractions such as the Hollywood Walk of Fame, Griffith Observatory, and Universal Studios Hollywood. According to the latest US Census data, the population of Los Angeles County, which includes the city of Los Angeles, is over 10 million people, making it the most populous county'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the model as we did before, except now using our new meta function that also saves chat to file\n",
    "invoke_model(prompt_text = 'What is the capital of Illinois?', current_session_id = demo_id_1)\n",
    "invoke_model(prompt_text = 'What is the capital of California?', current_session_id = demo_id_2)\n",
    "invoke_model(prompt_text = 'What is the largest city in that state?', current_session_id = demo_id_1)\n",
    "invoke_model(prompt_text = 'What is the largest city in that state?', current_session_id = demo_id_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Chat History from File\n",
    "Before we can call it a day, we need a means to now load this JSON chat history back from file into something that LangChain can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chat_history_from_file(chat_history_json_location):\n",
    "    '''\n",
    "    Loads the chat history from file\n",
    "\n",
    "    Inputs:\n",
    "        - chat_history_json_location (str): The location of where the chat history JSON file resides\n",
    "\n",
    "    Returns:\n",
    "        - user_history (dict): A dictionary representing the user history that will be saved back to file\n",
    "        - lc_user_conversation_history (dict): A LangChain managed version of the user's conversation history\n",
    "    '''\n",
    "\n",
    "    # Instantiating an empty dictionary to hold the LangChain (LC) user conversation history\n",
    "    lc_user_conversation_history = {}\n",
    "\n",
    "    # Loading the user history from the local JSON file\n",
    "    with open(chat_history_json_location, 'r') as f:\n",
    "        user_history = json.load(f)\n",
    "\n",
    "    # Iterating over each conversation in the user history\n",
    "    for conversation_id, conversation in user_history['chat_history'].items():\n",
    "        \n",
    "        # Instantiating a list to keep track of the chat interaction\n",
    "        chat_interaction = []\n",
    "\n",
    "        # Instantiating a LangChain chat message history object\n",
    "        lc_chat_message_history = ChatMessageHistory()\n",
    "\n",
    "        # Iterating over each chat interaction in the conversation history\n",
    "        for chat_interaction in conversation['conversation']:\n",
    "\n",
    "            # Appending any user messages as a LangChain HumanMessage\n",
    "            if chat_interaction['role'] == 'user':\n",
    "                lc_chat_message_history.add_message(HumanMessage(content = chat_interaction['content']))\n",
    "\n",
    "            # Appending any assistant messages as a LangChain AIMessage\n",
    "            if chat_interaction['role'] == 'assistant':\n",
    "                lc_chat_message_history.add_message(AIMessage(content = chat_interaction['content'], metadata = chat_interaction['metadata']))\n",
    "\n",
    "        # Appending the full conversation and metadata to the LC user conversation history with conversation ID as the key\n",
    "        lc_user_conversation_history[conversation_id] = lc_chat_message_history\n",
    "\n",
    "    return user_history, lc_user_conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in user history from file\n",
    "user_history, lc_user_conversation_history = load_chat_history_from_file(chat_history_json_location = chat_history_json_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Real Life Use Case\n",
    "Okay, we now have the essential basic framework to start using our chatbot and saving our chat history to a local JSON file. We will jump back and forth between different use cases to ensure that what we are building is resilient to everyday use. Let's first begin by starting from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the user's history from scratch\n",
    "lc_user_conversation_history = {}\n",
    "user_history = copy.deepcopy(BASE_USER_CONVERSATION_HISTORY_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating a First Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating demo ID 3 (Just to not confuse with varibles used previously in the notebook)\n",
    "demo_id_3 = 'conv_id_' + str.replace(str(uuid.uuid4()), '-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The capital city of Illinois is Springfield. It's located in the central part of the state and is the county seat of Sangamon County. Springfield is known for its rich history, including being the site of Abraham Lincoln's presidential library and his former home, which is now a National Historic Site.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the model to get a response for demo ID 3\n",
    "invoke_model(prompt_text = 'What is the capital of Illinois?', current_session_id = demo_id_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting a New (Second) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating demo ID 4 (Just to not confuse with varibles used previously in the notebook)\n",
    "demo_id_4 = 'conv_id_' + str.replace(str(uuid.uuid4()), '-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The capital city of California is Sacramento. Sacramento is located in the central part of the state and is known for its rich history, cultural diversity, and various attractions such as Old Sacramento, the California State Capitol, and the California State Railroad Museum. It's also the seat of government for California and is home to various state government offices and agencies.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the model to get a response for demo ID 4\n",
    "invoke_model(prompt_text = 'What is the capital of California?', current_session_id = demo_id_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumping Back to First Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The largest city in Illinois is Chicago. Chicago is located in the northeastern part of the state and is the third most populous city in the United States. It's known for its iconic skyline, major industries, cultural institutions, and its role as a global hub for commerce, transportation, and technology. Chicago is also famous for its architecture, museums, and its food scene, particularly its deep-dish pizza and Chicago-style hot dogs.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the model to get a response for demo ID 3\n",
    "invoke_model(prompt_text = 'What is the largest city in that state?', current_session_id = demo_id_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading It All Back In from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in user history from file\n",
    "user_history, lc_user_conversation_history = load_chat_history_from_file(chat_history_json_location = chat_history_json_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting a Third (Final) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating demo ID 5 (Just to not confuse with varibles used previously in the notebook)\n",
    "demo_id_5 = 'conv_id_' + str.replace(str(uuid.uuid4()), '-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York does not have a capital city because it is a state in the United States. The capital city of New York State is Albany. However, New York City is the most populous city in the state and the largest city in the United States, and it is not the capital city. Albany is located about 150 miles northwest of New York City.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the model to get a response for demo ID 5\n",
    "invoke_model(prompt_text = 'What is the capital of New York?', current_session_id = demo_id_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning to the First Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chicago offers a wide range of activities for visitors of all ages and interests. Here are some popular things to do in Chicago:\\n\\n1. Explore the city's iconic architecture: Take a river cruise or architectural boat tour to learn about the city's famous buildings and their architects.\\n2. Visit museums: Chicago is home to world-class museums such as the Art Institute of Chicago, the Museum of Science and Industry, and the Shedd Aquarium\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the model to get a response for demo ID 3\n",
    "invoke_model(prompt_text = 'What are some fun things to do in that city?', current_session_id = demo_id_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading it all in from file one last time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the user's history from scratch (to ensure everything loads from file correctly)\n",
    "lc_user_conversation_history = {}\n",
    "user_history = copy.deepcopy(BASE_USER_CONVERSATION_HISTORY_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_id_44642eb7_3066_4cd4_8d76_1e0279478cea': ChatMessageHistory(messages=[HumanMessage(content='What is the capital of Illinois?'), AIMessage(content=\"The capital city of Illinois is Springfield. It's located in the central part of the state and is the county seat of Sangamon County. Springfield is known for its rich history, including being the site of Abraham Lincoln's presidential library and his former home, which is now a National Historic Site.\", metadata={}), HumanMessage(content='What is the largest city in that state?'), AIMessage(content=\"The largest city in Illinois is Chicago. Chicago is located in the northeastern part of the state and is the third most populous city in the United States. It's known for its iconic skyline, major industries, cultural institutions, and its role as a global hub for commerce, transportation, and technology. Chicago is also famous for its architecture, museums, and its food scene, particularly its deep-dish pizza and Chicago-style hot dogs.\", metadata={}), HumanMessage(content='What are some fun things to do in that city?'), AIMessage(content=\"Chicago offers a wide range of activities for visitors of all ages and interests. Here are some popular things to do in Chicago:\\n\\n1. Explore the city's iconic architecture: Take a river cruise or architectural boat tour to learn about the city's famous buildings and their architects.\\n2. Visit museums: Chicago is home to world-class museums such as the Art Institute of Chicago, the Museum of Science and Industry, and the Shedd Aquarium\", metadata={'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'timestamp': '2024-05-02 14:57:26.868778+00:00', 'like_data': None, 'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}})]),\n",
       " 'conv_id_0e04b483_4980_4ebb_83a2_c151e0f5004e': ChatMessageHistory(messages=[HumanMessage(content='What is the capital of California?'), AIMessage(content=\"The capital city of California is Sacramento. Sacramento is located in the central part of the state and is known for its rich history, cultural diversity, and various attractions such as Old Sacramento, the California State Capitol, and the California State Railroad Museum. It's also the seat of government for California and is home to various state government offices and agencies.\", metadata={'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'timestamp': '2024-05-02 14:57:08.511932+00:00', 'like_data': None, 'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}})]),\n",
       " 'conv_id_7bde07e1_1845_492b_a0ef_b5839c93bacd': ChatMessageHistory(messages=[HumanMessage(content='What is the capital of New York?'), AIMessage(content='New York does not have a capital city because it is a state in the United States. The capital city of New York State is Albany. However, New York City is the most populous city in the state and the largest city in the United States, and it is not the capital city. Albany is located about 150 miles northwest of New York City.', metadata={'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'timestamp': '2024-05-02 14:57:19.764098+00:00', 'like_data': None, 'hyperparameters': {'temp': 0.7, 'max_tokens': 1000}})])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in user history from file\n",
    "user_history, lc_user_conversation_history = load_chat_history_from_file(chat_history_json_location = chat_history_json_location)\n",
    "lc_user_conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
