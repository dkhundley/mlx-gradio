{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral on MLX\n",
    "In this notebook, we demonstrate how to run the open source model **Mistral** on your Apple Silicon computer. This notebook will largely be based on [the example in Apple's GitHub repository](https://github.com/ml-explore/mlx-examples/tree/main/llms/mistral)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting constant values to represent model name and directory\n",
    "MODEL_NAME = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "BASE_DIRECTORY = '../models/'\n",
    "\n",
    "# Setting the full model directory path\n",
    "model_directory = f'{BASE_DIRECTORY}{MODEL_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:44<00:00,  7.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# Checking to see if the directory has already been created\n",
    "if os.path.exists(model_directory):\n",
    "\n",
    "    # Loading the tokenizer and model from local file\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_directory)\n",
    "\n",
    "else:\n",
    "\n",
    "    # Creating the new model directory\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "    # Downloading the tokenizer and model from HuggingFace\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # Saving the tokenizer and model to model directory\n",
    "    tokenizer.save_pretrained(save_directory = model_directory)\n",
    "    model.save_pretrained(save_directory = model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer.encode('Hello world!', return_tensors = 'pt')\n",
    "# outputs = model.generate(inputs, max_length = 5)\n",
    "# tokenizer.decode(outputs[0], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 11 files: 100%|██████████| 11/11 [00:00<00:00, 233016.89it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = Path(MODEL_NAME)\n",
    "model_path = Path(\n",
    "    snapshot_download(\n",
    "        repo_id = MODEL_NAME,\n",
    "        revision = None,\n",
    "        allow_patterns = [\n",
    "            '*.json',\n",
    "            '*.safetensors',\n",
    "            '*.py',\n",
    "            'tokenizer.model',\n",
    "            '*.tiktoken'\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/dkhundley/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/cf47bb3e18fe41a5351bc36eef76e9c900847c89')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: What is the capital of Illinois? Answer using the tone of Jar Jar Binks.\n",
      "\n",
      "\n",
      "Meesa talkin' 'bout the capital of Illinois, yessiree! It's Springfield, meesa say! Yessiree, Springfield it is! Binks know, Binks very smart!\n",
      "==========\n",
      "Prompt: 60.280 tokens-per-sec\n",
      "Generation: 25.956 tokens-per-sec\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load('../models/mlx_model')\n",
    "response = generate(model, tokenizer, prompt = 'What is the capital of Illinois? Answer using the tone of Jar Jar Binks.', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
